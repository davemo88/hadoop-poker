HADOOP POKER: amh564-dk2353

Our project used two sources of poker data to draw conclusions about poker strategy.
Our code submission includes 3 mapreduce programs and one Spark program.

1. IRC Feature Extraction
This cleans and organizes our first data source: an IRC-Poker database compiled by the University of Alberta.
The map reduce project has several steps
     --merge all the database's files into a set of chornological poker actions
     --remove invalid data (ex: instances when a player loses or a player's hands aren't revealed)
     --normalizes relevant values
     --outputs a set of feature vectors for use in our SVM.
     --the feature vector is of the form: <action, numPlayers, position, bank0, bank1, bank2, bank3, bank4, bank5, bank6, bank7, bank8, cards>
buildAndRun.sh was used to build and test the map reduce code
webscrape.py was used to download all the IRC data from the IRC database website. 

2. PokerStars Feature Extraction
This get feature vectors from the second data source: Professional Poker player Jaime
Staples' hand history for Jan-Oct 2015. See the mapper for an example of the data. 
Since the hand history formats hands in a very human-friendly way (i.e. not computer
friendly), we have to iterate through many lines of these files to produce a single
record to be used for our purposes. See comments in the mapper for the step-by-step
details.

3. Hand Strength Calculator
Both the IRC and PokerStars Feature Extraction programs represent the player's cards as a string (ex: 2cKd = 2 of clubs and King of diamonds). We ran the output of both the IRC and PokerStars map reduce program through this program to convert the string representation of the cards into a normalized value that can be used in our SVM. 

4. Spark SVMs with MLLib (poker_svm.py)
This program trains SVMs to predict if a hand should be played or folded. We train many
SVMs with different regularization parameters to find the best value. The input files
are the outputs of the Hand Strength Calculator.



